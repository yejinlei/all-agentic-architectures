#!/usr/bin/env python
import os
import sys
from typing import Annotated

from dotenv import load_dotenv



# coding: utf-8

# # ğŸ“˜ ä»£ç†æ¶æ„ 7ï¼šé»‘æ¿ç³»ç»Ÿ
# 
# æ¬¢è¿æ¥åˆ°æˆ‘ä»¬ä»£ç†æ¶æ„ç³»åˆ—çš„ç¬¬ä¸ƒä¸ªnotebookã€‚ä»Šå¤©ï¼Œæˆ‘ä»¬æ¢ç´¢**é»‘æ¿ç³»ç»Ÿ**ï¼Œä¸€ä¸ªå¼ºå¤§ä¸”é«˜åº¦çµæ´»çš„æ¨¡å¼ï¼Œç”¨äºåè°ƒå¤šä¸ªä¸“å®¶ä»£ç†ã€‚ è¿™ç§æ¶æ„åŸºäºä¸€ç»„äººç±»ä¸“å®¶å›´ç»•ç‰©ç†é»‘æ¿åä½œè§£å†³å¤æ‚é—®é¢˜çš„ç†å¿µå»ºæ¨¡ã€‚
# 
# ä¸åˆšæ€§çš„ã€é¢„å®šä¹‰çš„ä»£ç†äº¤æ¥åºåˆ—ä¸åŒï¼Œé»‘æ¿ç³»ç»Ÿå…·æœ‰ä¸€ä¸ªä¸­å¤®å…±äº«æ•°æ®å­˜å‚¨ï¼ˆ'é»‘æ¿'ï¼‰ï¼Œä»£ç†å¯ä»¥åœ¨å…¶ä¸­è¯»å–é—®é¢˜çš„å½“å‰çŠ¶æ€å¹¶å†™å…¥ä»–ä»¬çš„è´¡çŒ®ã€‚ ä¸€ä¸ªåŠ¨æ€çš„**æ§åˆ¶å™¨**è§‚å¯Ÿé»‘æ¿å¹¶æ ¹æ®æ¨è¿›è§£å†³æ–¹æ¡ˆæ‰€éœ€å†³å®šä¸‹ä¸€æ­¥æ¿€æ´»å“ªä¸ªä¸“å®¶ä»£ç†ã€‚è¿™å…è®¸æœºä¼šä¸»ä¹‰å’Œæ¶Œç°çš„å·¥ä½œæµç¨‹ã€‚
# 
# ä¸ºäº†çªå‡ºå…¶ç‹¬ç‰¹ä¼˜åŠ¿ï¼Œæˆ‘ä»¬å°†å…¶ä¸æˆ‘ä»¬ä¹‹å‰æ„å»ºçš„**é¡ºåºå¤šä»£ç†ç³»ç»Ÿ**è¿›è¡Œæ¯”è¾ƒã€‚æˆ‘ä»¬å°†å‘ä¸¤ä¸ªç³»ç»Ÿæå‡ºä¸€ä¸ªå¤æ‚çš„é‡‘èæŸ¥è¯¢ï¼Œå…¶ä¸­æœ€ä¼˜è·¯å¾„ä¸æ˜¯ç®€å•çš„â†’ B â†’ Cåºåˆ—ã€‚æˆ‘ä»¬å°†æ¼”ç¤ºåˆšæ€§é¡ºåºä»£ç†å¦‚ä½•éµå¾ªæ¬¡ä¼˜è·¯å¾„ï¼Œè€Œé»‘æ¿ç³»ç»Ÿçš„åŠ¨æ€æ§åˆ¶å™¨ä»¥æ›´åˆç†ã€æ•°æ®é©±åŠ¨çš„é¡ºåºæ¿€æ´»ä»£ç†ï¼Œä»è€Œäº§ç”Ÿæ›´é«˜æ•ˆå’Œè¿è´¯çš„åˆ†æã€‚

# ### å®šä¹‰
# **é»‘æ¿ç³»ç»Ÿ**æ˜¯ä¸€ç§å¤šä»£ç†æ¶æ„ï¼Œå…¶ä¸­å¤šä¸ªä¸“å®¶ä»£ç†é€šè¿‡è¯»å–å’Œå†™å…¥ç§°ä¸º'é»‘æ¿'çš„å…±äº«ä¸­å¤®æ•°æ®å­˜å‚¨åº“è¿›è¡Œåä½œã€‚ æ§åˆ¶å™¨æˆ–è°ƒåº¦å™¨æ ¹æ®é»‘æ¿ä¸Šè§£å†³æ–¹æ¡ˆçš„æ¼”å˜çŠ¶æ€åŠ¨æ€ç¡®å®šä¸‹ä¸€ä¸ªåº”è¯¥è¡ŒåŠ¨çš„ä»£ç†ã€‚
# 
# ### é«˜çº§å·¥ä½œæµç¨‹
# 
# 1. **å…±äº«å†…å­˜ï¼ˆé»‘æ¿ï¼‰ï¼š** ä¸€ä¸ªä¸­å¤®æ•°æ®ç»“æ„ä¿å­˜é—®é¢˜çš„å½“å‰çŠ¶æ€ï¼ŒåŒ…æ‹¬ç”¨æˆ·è¯·æ±‚ã€ä¸­é—´å‘ç°å’Œéƒ¨åˆ†è§£å†³æ–¹æ¡ˆã€‚
# 2. **ä¸“å®¶ä»£ç†ï¼š** ä¸€ç»„ç‹¬ç«‹çš„ä»£ç†ï¼Œæ¯ä¸ªéƒ½å…·æœ‰ç‰¹å®šçš„ä¸“ä¸šçŸ¥è¯†ï¼ŒæŒç»­ç›‘æ§é»‘æ¿ã€‚
# 3. **æ§åˆ¶å™¨ï¼š** ä¸€ä¸ªä¸­å¤®'æ§åˆ¶å™¨'ä»£ç†ä¹Ÿç›‘æ§é»‘æ¿ã€‚å®ƒçš„å·¥ä½œæ˜¯åˆ†æå½“å‰çŠ¶æ€å¹¶å†³å®šå“ªä¸ªä¸“å®¶ä»£ç†æœ€é€‚åˆåšå‡ºä¸‹ä¸€ä¸ªè´¡çŒ®ã€‚
# 4. **æœºä¼šä¸»ä¹‰æ¿€æ´»ï¼š** æ§åˆ¶å™¨æ¿€æ´»é€‰å®šçš„ä»£ç†ã€‚ä»£ç†ä»é»‘æ¿è¯»å–ç›¸å…³æ•°æ®ï¼Œæ‰§è¡Œå…¶ä»»åŠ¡ï¼Œå¹¶å°†å…¶å‘ç°å†™å›é»‘æ¿ã€‚
# 5. **è¿­ä»£ï¼š**è¿‡ç¨‹é‡å¤ï¼Œæ§åˆ¶å™¨ä»¥åŠ¨æ€åºåˆ—æ¿€æ´»ä¸åŒçš„ä»£ç†ï¼Œç›´åˆ°å®ƒç¡®å®šé»‘æ¿ä¸Šçš„è§£å†³æ–¹æ¡ˆå·²å®Œæˆã€‚
# 
# ### ä½•æ—¶ä½¿ç”¨/åº”ç”¨åœºæ™¯
# * **å¤æ‚ã€ç»“æ„ä¸è‰¯çš„é—®é¢˜ï¼š** é€‚ç”¨äºè§£å†³æ–¹æ¡ˆè·¯å¾„äº‹å…ˆæœªçŸ¥ä¸”éœ€è¦æ¶Œç°ã€æœºä¼šä¸»ä¹‰ç­–ç•¥çš„é—®é¢˜ï¼ˆä¾‹å¦‚ï¼Œå¤æ‚è¯Šæ–­ã€ç§‘å­¦å‘ç°ï¼‰ã€‚
# * **å¤šæ¨¡æ€ç³»ç»Ÿï¼š** åè°ƒå¤„ç†ä¸åŒæ•°æ®ç±»å‹ï¼ˆæ–‡æœ¬ã€å›¾åƒã€ä»£ç ï¼‰çš„ä»£ç†çš„å¥½æ–¹æ³•ï¼Œå› ä¸ºå®ƒä»¬éƒ½å¯ä»¥å°†å‘ç°å‘å¸ƒåˆ°å…±äº«é»‘æ¿ã€‚
# * **åŠ¨æ€æ„ä¹‰æ„å»ºï¼š** éœ€è¦ä»è®¸å¤šä¸åŒçš„å¼‚æ­¥æ¥æºç»¼åˆä¿¡æ¯çš„æƒ…å†µã€‚
# 
# ### ä¼˜ç‚¹å’Œç¼ºç‚¹
# * **ä¼˜ç‚¹ï¼š**
#  * **çµæ´»æ€§å’Œé€‚åº”æ€§ï¼š** å·¥ä½œæµç¨‹ä¸æ˜¯ç¡¬ç¼–ç çš„ï¼›å®ƒæ ¹æ®é—®é¢˜æ¶Œç°ï¼Œä½¿ç³»ç»Ÿé«˜åº¦è‡ªé€‚åº”ã€‚
#  * **æ¨¡å—åŒ–ï¼š** å¾ˆå®¹æ˜“æ·»åŠ æˆ–åˆ é™¤ä¸“å®¶ä»£ç†è€Œæ— éœ€é‡æ–°æ¶æ„æ•´ä¸ªç³»ç»Ÿã€‚
# * **ç¼ºç‚¹ï¼š**
#  * **æ§åˆ¶å™¨å¤æ‚æ€§ï¼š** æ•´ä¸ªç³»ç»Ÿçš„æ™ºèƒ½ä¸¥é‡ä¾èµ–äºæ§åˆ¶å™¨çš„å¤æ‚ç¨‹åº¦ã€‚å¤©çœŸçš„æ§åˆ¶å™¨å¯èƒ½å¯¼è‡´ä½æ•ˆæˆ–å¾ªç¯è¡Œä¸ºã€‚
#  * **è°ƒè¯•æŒ‘æˆ˜ï¼š** å·¥ä½œæµç¨‹çš„éçº¿æ€§ã€æ¶Œç°æ€§è´¨æœ‰æ—¶å¯èƒ½ä½¿å…¶æ¯”ç®€å•çš„é¡ºåºè¿‡ç¨‹æ›´éš¾è¿½è¸ªå’Œè°ƒè¯•ã€‚

# ## é˜¶æ®µ0ï¼šåŸºç¡€ä¸è®¾ç½®
# 
# æˆ‘ä»¬å°†ä»æ ‡å‡†è®¾ç½®è¿‡ç¨‹å¼€å§‹ï¼šå®‰è£…åº“å¹¶é…ç½®ç¡…åŸºæµåŠ¨å¹³å°ã€LangSmithå’ŒTavilyçš„APIå¯†é’¥ã€‚

# ### æ­¥éª¤0.1ï¼š å®‰è£…æ ¸å¿ƒåº“
# 
# **æˆ‘ä»¬å°†è¦åšçš„ï¼š**
# æˆ‘ä»¬å°†ä¸ºè¿™ä¸ªé¡¹ç›®ç³»åˆ—å®‰è£…æ ‡å‡†çš„åº“å¥—ä»¶ã€‚

# In[1]:


# !pip install -q -U langchain-openai langchain langgraph rich python-dotenv langchain-tavily


# ### æ­¥éª¤0.2ï¼š å¯¼å…¥åº“å’Œè®¾ç½®å¯†é’¥
# 
# **æˆ‘ä»¬å°†è¦åšçš„ï¼š**
# æˆ‘ä»¬å°†å¯¼å…¥å¿…è¦çš„æ¨¡å—å¹¶ä»`.env`æ–‡ä»¶åŠ è½½æˆ‘ä»¬çš„APIå¯†é’¥ã€‚
# 
# **éœ€è¦æ‰§è¡Œçš„æ“ä½œï¼š** åœ¨æ­¤ç›®å½•ä¸­åˆ›å»ºä¸€ä¸ªåŒ…å«æ‚¨çš„å¯†é’¥çš„`.env`æ–‡ä»¶ï¼š
# ```
# OPENAI_API_KEY="your_siliconflow_api_key_here"
# LANGCHAIN_API_KEY="your_langsmith_api_key_here"
# TAVILY_API_KEY="your_tavily_api_key_here"
# ```

# In[2]:


import os 
from typing import List, Annotated, TypedDict, Optional
 
from dotenv import load_dotenv

# PHOENIXè¿½è¸ªé…ç½®
import phoenix as px
from phoenix.otel import register

from opentelemetry.instrumentation.langchain import LangchainInstrumentor
from opentelemetry.instrumentation.openai import OpenAIInstrumentor
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(filename=f'phoenix_init_{os.path.basename(__file__)}.log', level=logging.INFO)
logger = logging.getLogger(__name__)

# LangChain components 
from langchain_openai import ChatOpenAI

from langchain_tavily import TavilySearch
from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage
 
from pydantic import BaseModel, Field 
from langchain_core.prompts import ChatPromptTemplate

# LangGraph components 
from langgraph.graph import StateGraph, END

# ç”¨äºç¾è§‚æ‰“å° 
from rich.console import Console

from rich.markdown import Markdown

# --- API Keyå’Œè¿½è¸ª Setup ---
load_dotenv()




os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = "Agentic Architecture - Blackboard (SiliconFlow)"
for key in ["OPENAI_API_KEY", "LANGCHAIN_API_KEY", "TAVILY_API_KEY"]:
    if not os.environ.get(key):
        print(f"{key} æœªæ‰¾åˆ°ã€‚è¯·åˆ›å»º.envæ–‡ä»¶å¹¶è®¾ç½®å¯†é’¥ã€‚")
# é…ç½®PHOENIXè¿½è¸ª
project_name = os.path.splitext(os.path.basename(__file__))[0]
try:
    logger.info(f"åˆå§‹åŒ–Phoenixè¿½è¸ªï¼Œé¡¹ç›®å: {project_name}")
    tracer_provider = register(project_name=project_name)
    LangchainInstrumentor().instrument(tracer_provider=tracer_provider)
    OpenAIInstrumentor().instrument(tracer_provider=tracer_provider)
    logger.info("Phoenixè¿½è¸ªåˆå§‹åŒ–æˆåŠŸ")
    print(f"PHOENIXè¿½è¸ªå·²é…ç½®ï¼Œé¡¹ç›®å: {project_name}")
except Exception as ex:
    logger.error(f"Phoenixè¿½è¸ªåˆå§‹åŒ–å¤±è´¥: {ex}")
    print(f"è­¦å‘Š: PHOENIXè¿½è¸ªåˆå§‹åŒ–å¤±è´¥: {ex}")


print("ç¯å¢ƒå˜é‡å·²åŠ è½½ï¼Œè¿½è¸ªè®¾ç½®å·²å®Œæˆã€‚")


# ## é˜¶æ®µ1ï¼šåŸºçº¿ - ä¿®æ­£çš„é¡ºåºå¤šä»£ç†ç³»ç»Ÿ
# 
# ä¸ºäº†ç†è§£é»‘æ¿çš„çµæ´»æ€§ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦ä¸€ä¸ªæ­£ç¡®è¿è¡Œçš„é¡ºåºç³»ç»Ÿã€‚åŸå§‹ç‰ˆæœ¬å¤±è´¥æ˜¯å› ä¸ºä¸“å®¶æ²¡æœ‰ä½¿ç”¨å‰é¢æ­¥éª¤çš„è¾“å‡ºã€‚æˆ‘ä»¬å°†é€šè¿‡ç¡®ä¿æ¯ä¸ªä»£ç†ä»çŠ¶æ€æ¥æ”¶å¿…è¦çš„ä¸Šä¸‹æ–‡æ¥çº æ­£è¿™ä¸€ç‚¹ã€‚

# ### æ­¥éª¤1.1ï¼šæ„å»ºä¿®æ­£çš„é¡ºåºå›¢é˜Ÿ
# 
# **æˆ‘ä»¬å°†è¦åšçš„ï¼š**
# æˆ‘ä»¬å°†å®šä¹‰æ˜ç¡®ä½¿ç”¨å…¶å‰ä»»è¾“å‡ºçš„ä¸“å®¶ä»£ç†ï¼Œç„¶åå°†å®ƒä»¬è¿æ¥æˆå›ºå®šçš„çº¿æ€§åºåˆ—ã€‚

# In[3]:


console = Console()
# Using a more capable model to handle complex instructions better
llm = ChatOpenAI(model="Qwen/Qwen2.5-72B-Instruct", base_url=os.environ.get("OPENAI_API_BASE"), temperature=0)
search_tool = TavilySearch(max_results=2)

# State for  sequential agent
class SequentialState(TypedDict):
 user_request: str
 news_report: Optional[str]
 technical_report: Optional[str]
 financial_report: Optional[str]
 final_report: Optional[str]

# --- CORRECTED SPECIALIST NODES FOR SEQUENTIAL AGENT ---
# Key change is that each agent now gets context from previous steps, not just original request.

def news_analyst_node_seq(state: SequentialState):
 console.print("--- (Sequential) è°ƒç”¨æ–°é—»åˆ†æå¸ˆ ---")
 prompt = f"ä½ çš„ä»»åŠ¡æ˜¯ä½œä¸ºä¸“ä¸šæ–°é—»åˆ†æå¸ˆã€‚æŸ¥æ‰¾ç”¨æˆ·è¯·æ±‚ä¸­ä¸»é¢˜çš„æœ€æ–°é‡å¤§æ–°é—»å¹¶æä¾›ç®€æ´æ‘˜è¦ã€‚\n\nç”¨æˆ·è¯·æ±‚: {state['user_request']}"
 agent = llm.bind_tools([search_tool])
 result = agent.invoke(prompt)
 return {"news_report": result.content}

def technical_analyst_node_seq(state: SequentialState):
 console.print("--- (Sequential) è°ƒç”¨æŠ€æœ¯åˆ†æå¸ˆ ---")
 # This agent now uses news report as context.
 prompt = f"ä½ çš„ä»»åŠ¡æ˜¯ä½œä¸ºä¸“ä¸šæŠ€æœ¯åˆ†æå¸ˆã€‚åŸºäºä»¥ä¸‹æ–°é—»æŠ¥å‘Šï¼Œå¯¹å…¬å¸è‚¡ç¥¨è¿›è¡ŒæŠ€æœ¯åˆ†æã€‚\n\næ–°é—»æŠ¥å‘Š:\n{state['news_report']}"
 agent = llm.bind_tools([search_tool])
 result = agent.invoke(prompt)
 return {"technical_report": result.content}

def financial_analyst_node_seq(state: SequentialState):
 console.print("--- (Sequential) è°ƒç”¨è´¢åŠ¡åˆ†æå¸ˆ ---")
 # This agent also uses news report as context.
 prompt = f"ä½ çš„ä»»åŠ¡æ˜¯ä½œä¸ºä¸“ä¸šè´¢åŠ¡åˆ†æå¸ˆã€‚åŸºäºä»¥ä¸‹æ–°é—»æŠ¥å‘Šï¼Œåˆ†æå…¬å¸æœ€è¿‘çš„è´¢åŠ¡è¡¨ç°ã€‚\n\næ–°é—»æŠ¥å‘Š:\n{state['news_report']}"
 agent = llm.bind_tools([search_tool])
 result = agent.invoke(prompt)
 return {"financial_report": result.content}


def report_writer_node_seq(state: SequentialState):
 console.print("--- (Sequential) è°ƒç”¨æŠ¥å‘Šæ’°å†™è€… ---")
 prompt = f"""ä½ æ˜¯ä¸€åä¸“ä¸šçš„æŠ¥å‘Šæ’°å†™è€…ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æ–°é—»ã€æŠ€æœ¯å’Œè´¢åŠ¡åˆ†æå¸ˆçš„ä¿¡æ¯ç»¼åˆæˆä¸€ä»½ç›´æ¥å›ç­”ç”¨æˆ·åŸå§‹è¯·æ±‚çš„è¿è´¯æŠ¥å‘Šã€‚

ç”¨æˆ·è¯·æ±‚: {state['user_request']}

ä»¥ä¸‹æ˜¯è¦åˆå¹¶çš„æŠ¥å‘Šï¼š
---
æ–°é—»æŠ¥å‘Š: {state['news_report']}
---
æŠ€æœ¯æŠ¥å‘Š: {state['technical_report']}
---
è´¢åŠ¡æŠ¥å‘Š: {state['financial_report']}
"""
 report = llm.invoke(prompt).content
 return {"final_report": report}

# Build sequential graph
seq_graph_builder = StateGraph(SequentialState)
seq_graph_builder.add_node("news", news_analyst_node_seq)
seq_graph_builder.add_node("tech", technical_analyst_node_seq)
seq_graph_builder.add_node("finance", financial_analyst_node_seq)
seq_graph_builder.add_node("writer", report_writer_node_seq)

# Rigid, hardcoded sequence
seq_graph_builder.set_entry_point("news")
seq_graph_builder.add_edge("news", "tech")
seq_graph_builder.add_edge("tech", "finance")
seq_graph_builder.add_edge("finance", "writer")
seq_graph_builder.add_edge("writer", END)

sequential_app = seq_graph_builder.compile()
print("ä¿®æ­£çš„é¡ºåºå¤šä»£ç†ç³»ç»Ÿç¼–è¯‘æˆåŠŸã€‚")


# ### æ­¥éª¤1.2ï¼šåœ¨åŠ¨æ€é—®é¢˜ä¸Šæµ‹è¯•é¡ºåºä»£ç†
# 
# ç°åœ¨é¡ºåºä»£ç†æ­£ç¡®ä¼ é€’ä¸Šä¸‹æ–‡ï¼Œè®©æˆ‘ä»¬è§‚å¯Ÿå…¶è¡Œä¸ºã€‚å®ƒå°†äº§ç”Ÿæ›´è¿è´¯çš„æŠ¥å‘Šï¼Œä½†å…¶*è¿‡ç¨‹*ä»å°†æ˜¯ä½æ•ˆçš„ï¼Œå¹¶ä¸”æ— æ³•éµå¾ªæ¡ä»¶é€»è¾‘ã€‚

# In[4]:


dynamic_query = "æŸ¥æ‰¾å…³äºNvidiaçš„æœ€æ–°é‡å¤§æ–°é—»ã€‚åŸºäºè¯¥æ–°é—»çš„æƒ…ç»ªï¼Œè¿›è¡ŒæŠ€æœ¯åˆ†æï¼ˆå¦‚æœæ–°é—»æ˜¯ä¸­æ€§æˆ–ç§¯æçš„ï¼‰æˆ–å¯¹å…¶æœ€è¿‘è¡¨ç°çš„è´¢åŠ¡åˆ†æï¼ˆå¦‚æœæ–°é—»æ˜¯è´Ÿé¢çš„ï¼‰ã€‚"

console.print(f"[bold yellow]æµ‹è¯•ä¿®æ­£çš„é¡ºåºä»£ç†åœ¨åŠ¨æ€æŸ¥è¯¢ä¸Š:[/bold yellow]\n'{dynamic_query}'\n")

# Run graph
final_seq_output = sequential_app.invoke({"user_request": dynamic_query})

console.print("\n--- [bold red]é¡ºåºä»£ç†çš„æœ€ç»ˆæŠ¥å‘Š[/bold red] ---")
console.print(Markdown(final_seq_output['final_report']))


# **ä¿®æ­£åè¾“å‡ºçš„è®¨è®ºï¼š**
# ä»£ç†ç°åœ¨äº§ç”Ÿå®Œæ•´ã€åˆç†çš„æŠ¥å‘Šã€‚ç„¶è€Œï¼Œæ‰§è¡Œè·Ÿè¸ª`News â†’ Technical â†’ Financial`æ­ç¤ºäº†å…¶æ ¹æœ¬ç¼ºé™·ã€‚å®ƒæ‰§è¡Œäº†**æŠ€æœ¯å’Œè´¢åŠ¡åˆ†æä¸¤è€…**ï¼Œå®Œå…¨å¿½ç•¥äº†ç”¨æˆ·çš„æ¡ä»¶è¯·æ±‚ï¼ˆ"è¦ä¹ˆ...è¦ä¹ˆ..."ï¼‰ã€‚è¿™æ˜¯ä½æ•ˆçš„ï¼Œå±•ç¤ºäº†æˆ‘ä»¬æ—¨åœ¨ç”¨é»‘æ¿æ¶æ„è§£å†³çš„åˆšæ€§ã€‚

# ## é˜¶æ®µ2ï¼šé«˜çº§æ–¹æ³• - ä¿®æ­£çš„é»‘æ¿ç³»ç»Ÿ
# 
# ç°åœ¨ï¼Œæˆ‘ä»¬å°†æ„å»ºé»‘æ¿ç³»ç»Ÿã€‚ä¿®å¤åŸå§‹å¾ªç¯è¡Œä¸ºçš„å…³é”®æ˜¯ä¸º**æ§åˆ¶å™¨**åˆ¶ä½œä¸€ä¸ªæ›´æ™ºèƒ½çš„æç¤ºï¼Œä½¿å…¶æ„è¯†åˆ°è‡ªå·±ä½œä¸ºæœ‰çŠ¶æ€è§„åˆ’å™¨çš„è§’è‰²ã€‚

# ### æ­¥éª¤2.1ï¼šå®šä¹‰é»‘æ¿å’Œä¿®æ­£çš„æ§åˆ¶å™¨
# 
# **æˆ‘ä»¬å°†è¦åšçš„ï¼š**
# 1. **é»‘æ¿çŠ¶æ€ï¼š** å®šä¹‰`BlackboardState`ä½œä¸ºå…±äº«å†…å­˜ã€‚
# 2. **ä¸“å®¶ä»£ç†ï¼š** å®šä¹‰ä¸“å®¶èŠ‚ç‚¹ã€‚å®ƒä»¬å°†ç±»ä¼¼äºæˆ‘ä»¬ä¹‹å‰çš„ä»£ç†ã€‚
# 3. **æ§åˆ¶å™¨ï¼ˆä¿®æ­£ï¼‰ï¼š** åˆ›å»ºä¸€ä¸ªå¥å£®çš„`controller_node`ï¼Œå…¶æç¤ºæ˜ç¡®æ¨ç†å·²å®Œæˆçš„æ­¥éª¤å’Œå‰©ä½™ç›®æ ‡ã€‚è¿™æ˜¯æœ€å…³é”®çš„æ›´æ”¹ã€‚

# In[5]:


# Blackboard State holds all infor mation
class BlackboardState(TypedDict):
 user_request: str
 # Central blackboard where agents post their findings as strings
 blackboard: List[str]
 # List of available agents for controller to choose from
 available_agents: List[str]
 # Controller's next decision
 next_agent: Optional[str]

# Pydantic model for  Controller's decision
# CORRECTION: Added list of available agents to field description to guide LLM's choice.
class ControllerDecision(BaseModel):
 next_agent: str = Field(description="è¦è°ƒç”¨çš„ä¸‹ä¸€ä¸ªä»£ç†çš„åç§°ã€‚å¿…é¡»æ˜¯['æ–°é—»åˆ†æå¸ˆ', 'æŠ€æœ¯åˆ†æå¸ˆ', 'è´¢åŠ¡åˆ†æå¸ˆ', 'æŠ¥å‘Šæ’°å†™è€…']ä¹‹ä¸€æˆ–'FINISH'ã€‚")
 reasoning: str = Field(description="é€‰æ‹©ä¸‹ä¸€ä¸ªä»£ç†çš„ç®€è¦åŸå› ã€‚")

# Reusable factory for  creating specialist agents for  blackboard
def create_blackboard_specialist(persona: str, agent_name: str):
    system_prompt = f"""ä½ æ˜¯ä¸€åä¸“ä¸šçš„ä¸“å®¶ä»£ç†ï¼š{persona}.
ä½ çš„ä»»åŠ¡æ˜¯é€šè¿‡æ‰§è¡Œä½ çš„ç‰¹å®šåŠŸèƒ½æ¥ä¸ºæ›´å¤§çš„ç›®æ ‡åšè´¡çŒ®ã€‚
é˜…è¯»åˆå§‹ç”¨æˆ·è¯·æ±‚å’Œå½“å‰é»‘æ¿ä»¥è·å–ä¸Šä¸‹æ–‡ã€‚
ä½¿ç”¨ä½ çš„å·¥å…·æŸ¥æ‰¾æ‰€éœ€ä¿¡æ¯ã€‚
æœ€åï¼Œå°†ä½ ç®€æ´çš„markdownæŠ¥å‘Šå‘å¸ƒå›é»‘æ¿ã€‚ä½ çš„æŠ¥å‘Šåº”è¯¥ç”¨ä½ çš„åå­—ç­¾å '{agent_name}'ã€‚
"""
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "ç”¨æˆ·è¯·æ±‚: {user_request}\n\né»‘æ¿ï¼ˆä¹‹å‰çš„æŠ¥å‘Šï¼‰:\n{blackboard_str}")
    ])
    
    # åˆ›å»ºä¸€ä¸ªå¸¦å·¥å…·è°ƒç”¨çš„LLMé“¾
    def agent_chain(inputs):
        try:
            # ç¬¬ä¸€æ­¥ï¼šè·å–å·¥å…·è°ƒç”¨è¯·æ±‚
            result = (prompt_template | llm.bind_tools([search_tool])).invoke(inputs)
            
            # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå·¥å…·
            if hasattr(result, 'tool_calls') and result.tool_calls:
                console.print(f"[DEBUG] æ‰§è¡Œå·¥å…·è°ƒç”¨: {result.tool_calls}")
                
                # æ”¶é›†å·¥å…·è°ƒç”¨ç»“æœ
                tool_results = []
                for tool_call in result.tool_calls:
                    if tool_call["name"] == "tavily_search":
                        # æ‰§è¡ŒTavilyæœç´¢
                        search_result = search_tool.invoke(tool_call["args"])
                        tool_results.append({
                            "tool_call": tool_call,
                            "result": search_result
                        })
                
                # ç¬¬äºŒæ­¥ï¼šå°†å·¥å…·ç»“æœè¿”å›ç»™LLMï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
                final_prompt = ChatPromptTemplate.from_messages([
                    ("system", system_prompt),
                    ("human", "ç”¨æˆ·è¯·æ±‚: {user_request}\n\né»‘æ¿ï¼ˆä¹‹å‰çš„æŠ¥å‘Šï¼‰:\n{blackboard_str}"),
                    ("ai", result.content if hasattr(result, 'content') else ""),
                    ("human", "å·¥å…·ç»“æœ: {tool_results}")
                ])
                
                # å°†å·¥å…·ç»“æœæ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²
                tool_results_str = "\n\n".join([
                    f"å·¥å…·: {tr['tool_call']['name']}\nå‚æ•°: {tr['tool_call']['args']}\nç»“æœ: {tr['result']}"
                    for tr in tool_results
                ])
                
                # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
                final_result = final_prompt | llm
                report_content = final_result.invoke({
                    "user_request": inputs["user_request"],
                    "blackboard_str": inputs["blackboard_str"],
                    "tool_results": tool_results_str
                })
                
                return report_content.content if hasattr(report_content, 'content') else str(report_content)
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›ç»“æœ
                return result.content if hasattr(result, 'content') else "æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆå†…å®¹"
        except Exception as e:
            console.print(f"[ERROR] ä¸“å®¶ä»£ç†æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            # ä½¿ç”¨é»˜è®¤å€¼ä½œä¸ºé™çº§ç­–ç•¥
            return f"{agent_name}æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"

    def specialist_node(state: BlackboardState):
        console.print(f"--- (é»‘æ¿) ä»£ç† '{agent_name}' æ­£åœ¨å·¥ä½œ... ---")
        blackboard_str = "\n---\n".join(state["blackboard"])
        
        # æ‰§è¡Œä»£ç†é“¾ï¼Œè·å–æŠ¥å‘Šå†…å®¹
        report_content = agent_chain({
            "user_request": state["user_request"], 
            "blackboard_str": blackboard_str
        })
        
        report = f"**æŠ¥å‘Šæ¥è‡ª{agent_name}:**\n{report_content}"
        # Debug: æ£€æŸ¥å®Œæ•´æŠ¥å‘Šå†…å®¹
        console.print(f"[DEBUG] å®Œæ•´æŠ¥å‘Šå†…å®¹: {report}")
        console.print(f"[DEBUG] æŠ¥å‘Šé•¿åº¦: {len(report)} å­—ç¬¦")
        # Append new report to list of blackboard entries
        new_blackboard = state["blackboard"] + [report]
        console.print(f"[DEBUG] é»‘æ¿æ›´æ–°å‰é•¿åº¦: {len(state['blackboard'])}, æ›´æ–°åé•¿åº¦: {len(new_blackboard)}")
        return {"blackboard": new_blackboard}
    return specialist_node

# Create specialist agent nodes
news_analyst_bb = create_blackboard_specialist("æ–°é—»åˆ†æå¸ˆ", "æ–°é—»åˆ†æå¸ˆ")
technical_analyst_bb = create_blackboard_specialist("æŠ€æœ¯åˆ†æå¸ˆ", "æŠ€æœ¯åˆ†æå¸ˆ")
financial_analyst_bb = create_blackboard_specialist("è´¢åŠ¡åˆ†æå¸ˆ", "è´¢åŠ¡åˆ†æå¸ˆ")
report_writer_bb = create_blackboard_specialist("ä»é»‘æ¿ç»¼åˆæœ€ç»ˆç­”æ¡ˆçš„æŠ¥å‘Šæ’°å†™è€…", "æŠ¥å‘Šæ’°å†™è€…")

# --- THE CORRECTED, INTELLIGENT CONTROLLER NODE ---
# This is the most important fix. The prompt is now much more sophisticated.
def controller_node(state: BlackboardState):
    console.print("--- æ§åˆ¶å™¨: åˆ†æé»‘æ¿ä¸­... ---")

    blackboard_content = "\n\n".join(state['blackboard'])
    agent_list = state['available_agents']

    # æ·»åŠ è¯¦ç»†è°ƒè¯•ä¿¡æ¯ï¼Œæ˜¾ç¤ºé»‘æ¿çš„åŸå§‹å†…å®¹
    console.print(f"[DEBUG] é»‘æ¿æ¡ç›®æ•°é‡: {len(state['blackboard'])}")
    for i, entry in enumerate(state['blackboard']):
        console.print(f"[DEBUG] é»‘æ¿æ¡ç›® {i} åŸå§‹å†…å®¹:\n{repr(entry)}")
        console.print(f"[DEBUG] é»‘æ¿æ¡ç›® {i} å‰50å­—ç¬¦: {entry[:50]}")
    console.print(f"[DEBUG] æ§åˆ¶å™¨æ¥æ”¶åˆ°çš„é»‘æ¿å†…å®¹:\n{blackboard_content}")
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æƒ…ç»ªåˆ†æä¿¡æ¯
    has_sentiment = False
    sentiment_keywords = ['ç§¯æ', 'ä¸­æ€§', 'è´Ÿé¢', 'æƒ…ç»ªåˆ†æ']
    for i, entry in enumerate(state['blackboard']):
        if any(keyword in entry for keyword in sentiment_keywords):
            has_sentiment = True
            console.print(f"[DEBUG] åœ¨é»‘æ¿æ¡ç›® {i} ä¸­æ£€æµ‹åˆ°æƒ…ç»ªåˆ†æä¿¡æ¯")
            break
    if not has_sentiment:
        console.print(f"[DEBUG] æœªåœ¨é»‘æ¿å†…å®¹ä¸­æ£€æµ‹åˆ°æƒ…ç»ªåˆ†æä¿¡æ¯")

    # New prompt is state-aware and goal-oriented.
    # æ„å»ºåŸºæœ¬æç¤ºï¼Œä½¿ç”¨åŒå¤§æ‹¬å·è½¬ä¹‰JSONä¸­çš„å­—é¢é‡å¤§æ‹¬å·
    base_prompt = """ä½ æ˜¯å¤šä»£ç†ç³»ç»Ÿçš„ä¸­å¤®æ§åˆ¶å™¨ã€‚ä½ çš„å·¥ä½œæ˜¯åˆ†æå…±äº«é»‘æ¿å’ŒåŸå§‹ç”¨æˆ·è¯·æ±‚ï¼Œå†³å®šä¸‹ä¸€ä¸ªåº”è¯¥è¿è¡Œå“ªä¸ªä¸“å®¶ä»£ç†ã€‚

**åŸå§‹ç”¨æˆ·è¯·æ±‚ï¼š**
{user_request}

**å½“å‰é»‘æ¿å†…å®¹ï¼š**
---
{blackboard_content}
---

**å¯ç”¨ä¸“å®¶ä»£ç†ï¼š**
{agent_list}

**é»‘æ¿å†…å®¹æ ¼å¼è¯´æ˜ï¼š**
é»‘æ¿ä¸Šçš„æ¯ä¸ªæŠ¥å‘Šéƒ½ä»¥"**æŠ¥å‘Šæ¥è‡ª[ä»£ç†åç§°]:**"çš„æ ¼å¼å¼€å¤´ï¼Œä¾‹å¦‚"**æŠ¥å‘Šæ¥è‡ªæ–°é—»åˆ†æå¸ˆ:**"ã€‚
è¯·ä»”ç»†æ£€æŸ¥é»‘æ¿å†…å®¹ï¼Œè¯†åˆ«å·²å®Œæˆå·¥ä½œçš„ä»£ç†åç§°å’Œä»–ä»¬çš„è´¡çŒ®ã€‚

**å·²å®Œæˆçš„ä»£ç†å’Œä»»åŠ¡ï¼š**
- è¯·ä»”ç»†æ£€æŸ¥å½“å‰é»‘æ¿å†…å®¹ï¼Œåˆ—å‡ºæ‰€æœ‰å·²ç»å®Œæˆå·¥ä½œçš„ä»£ç†åç§°

**ä½ çš„ä»»åŠ¡ï¼š**
1. ä»”ç»†é˜…è¯»ç”¨æˆ·è¯·æ±‚å’Œå½“å‰é»‘æ¿å†…å®¹
2. è¯†åˆ«å·²å®Œæˆçš„ä»£ç†å’Œä»–ä»¬çš„è´¡çŒ®
3. ç¡®å®šè¿˜éœ€è¦å®Œæˆå“ªäº›ä»»åŠ¡æ‰èƒ½æ»¡è¶³ç”¨æˆ·è¯·æ±‚
4. ä»å¯ç”¨ä»£ç†åˆ—è¡¨ä¸­é€‰æ‹©å•ä¸ªæœ€ä½³ä»£ç†æ¥æ‰§è¡Œä¸‹ä¸€æ­¥ï¼Œé¿å…é‡å¤è°ƒç”¨å·²ç»å®Œæˆå·¥ä½œçš„ä»£ç†
5. å¦‚æœæ‰€æœ‰å¿…è¦ä¿¡æ¯éƒ½å·²æ”¶é›†ï¼Œè°ƒç”¨"æŠ¥å‘Šæ’°å†™è€…"æ¥ç»¼åˆæœ€ç»ˆç­”æ¡ˆ
6. å¦‚æœæœ€ç»ˆæŠ¥å‘Šå·²æ’°å†™å®Œæˆï¼Œé€‰æ‹©'FINISH'

**å†³ç­–é€»è¾‘ï¼š**
- å¦‚æœé»‘æ¿å†…å®¹ä¸ºç©ºï¼ˆå³æ²¡æœ‰ä»»ä½•"**æŠ¥å‘Šæ¥è‡ª[ä»£ç†åç§°]:**"æ ¼å¼çš„å†…å®¹ï¼‰ï¼šé¦–å…ˆè°ƒç”¨"æ–°é—»åˆ†æå¸ˆ"è·å–æœ€æ–°æ–°é—»
- å¦‚æœå·²æœ‰æ–°é—»æŠ¥å‘Šï¼ˆå³é»‘æ¿ä¸Šæœ‰"**æŠ¥å‘Šæ¥è‡ªæ–°é—»åˆ†æå¸ˆ:**"çš„å†…å®¹ï¼‰ï¼š
  1. ä»”ç»†é˜…è¯»æ–°é—»æŠ¥å‘Šï¼Œå¯»æ‰¾æƒ…ç»ªåˆ†æéƒ¨åˆ†ï¼ˆé€šå¸¸åŒ…å«"ç§¯æ"ã€"ä¸­æ€§"æˆ–"è´Ÿé¢"ç­‰å…³é”®è¯ï¼‰
  2. å¦‚æœæ–°é—»æƒ…ç»ªä¸ºç§¯ææˆ–ä¸­æ€§ï¼Œè°ƒç”¨"æŠ€æœ¯åˆ†æå¸ˆ"
  3. å¦‚æœæ–°é—»æƒ…ç»ªä¸ºè´Ÿé¢ï¼Œè°ƒç”¨"è´¢åŠ¡åˆ†æå¸ˆ"
- å¦‚æœå·²æœ‰æŠ€æœ¯æˆ–è´¢åŠ¡åˆ†ææŠ¥å‘Šï¼ˆå³é»‘æ¿ä¸Šæœ‰"**æŠ¥å‘Šæ¥è‡ªæŠ€æœ¯åˆ†æå¸ˆ:**"æˆ–"**æŠ¥å‘Šæ¥è‡ªè´¢åŠ¡åˆ†æå¸ˆ:**"çš„å†…å®¹ï¼‰ï¼šè°ƒç”¨"æŠ¥å‘Šæ’°å†™è€…"ç»¼åˆæœ€ç»ˆç­”æ¡ˆ
- å¦‚æœå·²æœ‰æœ€ç»ˆæŠ¥å‘Šï¼ˆå³é»‘æ¿ä¸Šæœ‰"**æŠ¥å‘Šæ¥è‡ªæŠ¥å‘Šæ’°å†™è€…:**"çš„å†…å®¹ï¼‰ï¼šç«‹å³é€‰æ‹©'FINISH'ï¼Œä¸è¦å†æ¬¡è°ƒç”¨ä»»ä½•ä»£ç†

**é‡è¦æç¤ºï¼š**
- ä¸€æ—¦"æŠ¥å‘Šæ’°å†™è€…"å®Œæˆäº†å·¥ä½œå¹¶å°†æŠ¥å‘Šå‘å¸ƒåˆ°é»‘æ¿ä¸Šï¼Œä½ å¿…é¡»ç«‹å³è°ƒç”¨'FINISH'ï¼Œä¸å¾—å†è°ƒç”¨ä»»ä½•ä»£ç†
- è¯·ä»”ç»†æ£€æŸ¥é»‘æ¿å†…å®¹ä¸­æ˜¯å¦åŒ…å«"**æŠ¥å‘Šæ¥è‡ªæŠ¥å‘Šæ’°å†™è€…:**"çš„æ ¼å¼ï¼Œå¦‚æœ‰åˆ™å¿…é¡»è°ƒç”¨'FINISH'

**è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ï¼ŒåŒ…å«ä¸”ä»…åŒ…å«next_agentå’Œreasoningä¸¤ä¸ªå­—æ®µï¼š
```json
{{
  "next_agent": "[è¦è°ƒç”¨çš„ä»£ç†åç§°æˆ–'FINISH']",
  "reasoning": "[é€‰æ‹©è¯¥ä»£ç†çš„åŸå› ]"
}}
```

å…¶ä¸­next_agentå¿…é¡»æ˜¯å¯ç”¨ä»£ç†åˆ—è¡¨ä¸­çš„ä¸€ä¸ªæˆ–'FINISH'ï¼Œreasoningæ˜¯å¯¹é€‰æ‹©çš„ç®€è¦è§£é‡Šã€‚
"""

    prompt = base_prompt.format(
        user_request=state['user_request'],
        blackboard_content=blackboard_content if blackboard_content else "é»‘æ¿å½“å‰ä¸ºç©ºã€‚",
        agent_list=', '.join(agent_list)
    )

    try:
        # å°è¯•ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º
        controller_llm = llm.with_structured_output(ControllerDecision)
        decision_result = controller_llm.invoke(prompt)
        console.print(f"--- æ§åˆ¶å™¨: å†³å®šè°ƒç”¨ '{decision_result.next_agent}'ã€‚åŸå› ï¼š{decision_result.reasoning} ---")
        return {"next_agent": decision_result.next_agent}
    except Exception as e:
        console.print(f"[ERROR] æ§åˆ¶å™¨ç»“æ„åŒ–è¾“å‡ºå¤±è´¥: {e}")
        console.print("[DEBUG] å°è¯•æ‰‹åŠ¨è§£ææ§åˆ¶å™¨å“åº”...")
        
        # å¤‡é€‰æ–¹æ¡ˆï¼šæ‰‹åŠ¨è§£æJSONå“åº”
        try:
            # ç›´æ¥è·å–åŸå§‹å“åº”
            response = llm.invoke(prompt)
            content = response.content
            
            # æ¸…ç†å“åº”å†…å®¹ï¼Œç§»é™¤markdownä»£ç å—
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            content = content.strip()
            
            # å°è¯•æ‰‹åŠ¨è§£æJSONå“åº”
            import json
            decision_data = json.loads(content)
            
            # éªŒè¯å¿…å¡«å­—æ®µæ˜¯å¦å­˜åœ¨
            required_fields = ['next_agent', 'reasoning']
            for field in required_fields:
                if field not in decision_data:
                    raise ValueError(f"ç¼ºå°‘å¿…å¡«å­—æ®µ: {field}")
            
            # éªŒè¯next_agentå€¼æ˜¯å¦æœ‰æ•ˆ
            valid_agents = agent_list + ['FINISH']
            if decision_data['next_agent'] not in valid_agents:
                raise ValueError(f"æ— æ•ˆçš„ä»£ç†åç§°: {decision_data['next_agent']}ï¼Œå¿…é¡»æ˜¯{valid_agents}ä¹‹ä¸€")
            
            console.print(f"--- æ§åˆ¶å™¨: å†³å®šè°ƒç”¨ '{decision_data['next_agent']}'ã€‚åŸå› ï¼š{decision_data['reasoning']} ---")
            return {"next_agent": decision_data['next_agent']}
            
        except json.JSONDecodeError as e:
            console.print(f"[ERROR] æ§åˆ¶å™¨å“åº”JSONè§£æå¤±è´¥: {e}")
        except ValueError as e:
            console.print(f"[ERROR] æ§åˆ¶å™¨å“åº”å­—æ®µéªŒè¯å¤±è´¥: {e}")
        except Exception as e:
            console.print(f"[ERROR] æ§åˆ¶å™¨æ‰‹åŠ¨è§£æå¤±è´¥: {e}")
        
        # ä½¿ç”¨é»˜è®¤å€¼ä½œä¸ºé™çº§ç­–ç•¥
        console.print("[ERROR] æ§åˆ¶å™¨æ— æ³•ç”Ÿæˆæœ‰æ•ˆå†³ç­–ï¼Œä½¿ç”¨é»˜è®¤é€»è¾‘...")
        
        # åŸºäºé»‘æ¿å†…å®¹çš„ç®€å•é»˜è®¤é€»è¾‘
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æŠ¥å‘Šæ’°å†™è€…çš„æŠ¥å‘Š
        has_writer_report = any("**æŠ¥å‘Šæ¥è‡ªæŠ¥å‘Šæ’°å†™è€…:**" in report for report in state['blackboard'])
        if has_writer_report:
            console.print("--- æ§åˆ¶å™¨: æ£€æµ‹åˆ°æŠ¥å‘Šæ’°å†™è€…å·²å®Œæˆï¼Œå†³å®šè°ƒç”¨ 'FINISH' ---")
            return {"next_agent": "FINISH"}
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æŠ€æœ¯æˆ–è´¢åŠ¡åˆ†ææŠ¥å‘Š
        has_tech_or_fin_report = any(
            "**æŠ¥å‘Šæ¥è‡ªæŠ€æœ¯åˆ†æå¸ˆ:**" in report or "**æŠ¥å‘Šæ¥è‡ªè´¢åŠ¡åˆ†æå¸ˆ:**" in report 
            for report in state['blackboard']
        )
        if has_tech_or_fin_report:
            console.print("--- æ§åˆ¶å™¨: æ£€æµ‹åˆ°æŠ€æœ¯æˆ–è´¢åŠ¡åˆ†ææŠ¥å‘Šï¼Œå†³å®šè°ƒç”¨ 'æŠ¥å‘Šæ’°å†™è€…' ---")
            return {"next_agent": "æŠ¥å‘Šæ’°å†™è€…"}
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ–°é—»æŠ¥å‘Š
        has_news_report = any("**æŠ¥å‘Šæ¥è‡ªæ–°é—»åˆ†æå¸ˆ:**" in report for report in state['blackboard'])
        if has_news_report:
            # é»˜è®¤è°ƒç”¨æŠ€æœ¯åˆ†æå¸ˆï¼ˆç§¯æ/ä¸­æ€§æ–°é—»ï¼‰
            console.print("--- æ§åˆ¶å™¨: æ£€æµ‹åˆ°æ–°é—»æŠ¥å‘Šï¼Œé»˜è®¤å†³å®šè°ƒç”¨ 'æŠ€æœ¯åˆ†æå¸ˆ' ---")
            return {"next_agent": "æŠ€æœ¯åˆ†æå¸ˆ"}
        
        # é»˜è®¤è°ƒç”¨æ–°é—»åˆ†æå¸ˆ
        console.print("--- æ§åˆ¶å™¨: é»‘æ¿ä¸ºç©ºï¼Œé»˜è®¤å†³å®šè°ƒç”¨ 'æ–°é—»åˆ†æå¸ˆ' ---")
        return {"next_agent": "æ–°é—»åˆ†æå¸ˆ"}

print("é»‘æ¿ç»„ä»¶å’Œä¿®æ­£çš„æ§åˆ¶å™¨èŠ‚ç‚¹å·²å®šä¹‰ã€‚")


# ### æ­¥éª¤2.2ï¼šæ„å»ºé»‘æ¿å›¾
# 
# ç°åœ¨æˆ‘ä»¬å°†ç»„ä»¶è¿æ¥æˆåŠ¨æ€çŠ¶æ€å›¾ã€‚æ§åˆ¶å™¨å……å½“ä¸­å¤®è·¯ç”±å™¨ã€‚ä»»ä½•ä¸“å®¶è¿è¡Œåï¼Œæ§åˆ¶æ€»æ˜¯è¿”å›åˆ°æ§åˆ¶å™¨æ¥å†³å®šä¸‹ä¸€æ­¥ã€‚

# In[6]:


bb_graph_builder = StateGraph(BlackboardState)

# Add all nodes to graph
bb_graph_builder.add_node("Controller", controller_node)
bb_graph_builder.add_node("æ–°é—»åˆ†æå¸ˆ", news_analyst_bb)
bb_graph_builder.add_node("æŠ€æœ¯åˆ†æå¸ˆ", technical_analyst_bb)
bb_graph_builder.add_node("è´¢åŠ¡åˆ†æå¸ˆ", financial_analyst_bb)
bb_graph_builder.add_node("æŠ¥å‘Šæ’°å†™è€…", report_writer_bb)

bb_graph_builder.set_entry_point("Controller")

# This function defines dynamic routing logic based on Controller's decision
def route_to_agent(state: BlackboardState):
 return state["next_agent"]

# Conditional edges route from Controller to chosen specialist or to end
bb_graph_builder.add_conditional_edges(
 "Controller",
 route_to_agent,
 {
 "æ–°é—»åˆ†æå¸ˆ": "æ–°é—»åˆ†æå¸ˆ",
 "æŠ€æœ¯åˆ†æå¸ˆ": "æŠ€æœ¯åˆ†æå¸ˆ",
 "è´¢åŠ¡åˆ†æå¸ˆ": "è´¢åŠ¡åˆ†æå¸ˆ",
 "æŠ¥å‘Šæ’°å†™è€…": "æŠ¥å‘Šæ’°å†™è€…",
 "FINISH": END
 }
)

# After any specialist runs, control always returns to Controller for  next decision
bb_graph_builder.add_edge("æ–°é—»åˆ†æå¸ˆ", "Controller")
bb_graph_builder.add_edge("æŠ€æœ¯åˆ†æå¸ˆ", "Controller")
bb_graph_builder.add_edge("è´¢åŠ¡åˆ†æå¸ˆ", "Controller")
bb_graph_builder.add_edge("æŠ¥å‘Šæ’°å†™è€…", "Controller")

blackboard_app = bb_graph_builder.compile()
print("é»‘æ¿ç³»ç»Ÿç¼–è¯‘æˆåŠŸã€‚")


# ## é˜¶æ®µ3ï¼šæ­£é¢å¯¹æ¯”
# 
# è®©æˆ‘ä»¬åœ¨ç›¸åŒçš„åŠ¨æ€ä»»åŠ¡ä¸Šè¿è¡Œæˆ‘ä»¬æ–°çš„é»‘æ¿ç³»ç»Ÿå¹¶è§‚å¯Ÿå…¶æ™ºèƒ½å·¥ä½œæµç¨‹ã€‚

# In[7]:


console.print(f"[bold green]æµ‹è¯•é»‘æ¿ç³»ç»Ÿåœ¨ç›¸åŒçš„åŠ¨æ€æŸ¥è¯¢ä¸Š:[/bold green]\n'{dynamic_query}'\n")

agent_list = ["æ–°é—»åˆ†æå¸ˆ", "æŠ€æœ¯åˆ†æå¸ˆ", "è´¢åŠ¡åˆ†æå¸ˆ", "æŠ¥å‘Šæ’°å†™è€…"]
initial_bb_input = {"user_request": dynamic_query, "blackboard": [], "available_agents": agent_list}

# ä½¿ç”¨invokeè·å–æœ€ç»ˆçŠ¶æ€
final_bb_output = blackboard_app.invoke(initial_bb_input, {"recursion_limit": 10})
# ç¾è§‚æ‰“å°é»‘æ¿ä¸­çš„æ¯ä¸ªæŠ¥å‘Š
console.print("\n--- [bold purple]æœ€ç»ˆé»‘æ¿çŠ¶æ€[/bold purple] ---")
for  i, report in enumerate(final_bb_output.get('blackboard', [])):
    console.print(f"--- æŠ¥å‘Š {i+1} ---")
    console.print(Markdown(report))
    console.print("\n")

console.print("\n--- [bold green]é»‘æ¿ç³»ç»Ÿæœ€ç»ˆæŠ¥å‘Š[/bold green] ---")
# æœ€ç»ˆæŠ¥å‘Šæ˜¯æ’°å†™è€…å‘å¸ƒåˆ°é»‘æ¿çš„æœ€åä¸€é¡¹
final_report_content = final_bb_output['blackboard'][-1]
console.print(Markdown(final_report_content))


# **ä¿®æ­£åè¾“å‡ºçš„è®¨è®ºï¼š**
# æˆåŠŸï¼`GraphRecursionError`å·²æ¶ˆå¤±ã€‚æ‰§è¡Œè·Ÿè¸ªæ­ç¤ºäº†ä¸€ä¸ªæ›´æ™ºèƒ½çš„è¿‡ç¨‹ï¼š
# 
# 1. **æ§åˆ¶å™¨å¯åŠ¨ï¼š** æ§åˆ¶å™¨å¯åŠ¨ï¼Œçœ‹åˆ°ç©ºé»‘æ¿ï¼Œæ­£ç¡®å†³å®šé¦–å…ˆè°ƒç”¨**æ–°é—»åˆ†æå¸ˆ**ã€‚
# 2. **æ–°é—»åˆ†æå¸ˆè¿è¡Œï¼š** æ–°é—»åˆ†æå¸ˆæ‰¾åˆ°æœ€æ–°æ–°é—»å¹¶å°†å…¶æŠ¥å‘Šå‘å¸ƒåˆ°é»‘æ¿ã€‚
# 3. **æ§åˆ¶å™¨é‡æ–°è¯„ä¼°ï¼š** æ§åˆ¶è¿”å›åˆ°æ§åˆ¶å™¨ã€‚å®ƒè¯»å–æ–°é—»åˆ†æå¸ˆçš„æŠ¥å‘Šï¼Œç†è§£æƒ…ç»ªï¼Œå¹¶éµå¾ªç”¨æˆ·çš„é€»è¾‘ã€‚å®ƒæ™ºèƒ½åœ°å†³å®šè°ƒç”¨é€‚å½“çš„ä¸‹ä¸€ä¸ªåˆ†æå¸ˆï¼ˆ**æŠ€æœ¯**æˆ–**è´¢åŠ¡**ï¼‰ï¼Œå®Œå…¨è·³è¿‡å¦ä¸€ä¸ªã€‚
# 4. **ä¸“å®¶è¿è¡Œï¼š** é€‰å®šçš„åˆ†æå¸ˆæ‰§è¡Œå…¶ä»»åŠ¡å¹¶å°†å…¶æŠ¥å‘Šæ·»åŠ åˆ°é»‘æ¿ã€‚
# 5. **æ§åˆ¶å™¨å®Œæˆï¼š** æ§åˆ¶å™¨çœ‹åˆ°æ‰€æœ‰å¿…è¦çš„åˆ†æå·²å®Œæˆï¼Œå¹¶è°ƒç”¨**æŠ¥å‘Šæ’°å†™è€…**æ¥ç»¼åˆæœ€ç»ˆç­”æ¡ˆã€‚
# 6. **æœ€ç»ˆè°ƒç”¨ï¼š** æ’°å†™è€…å‘å¸ƒæœ€ç»ˆæŠ¥å‘Šåï¼Œæ§åˆ¶å™¨çœ‹åˆ°è¿™ä¸€ç‚¹å¹¶å†³å®š**å®Œæˆ**ã€‚
# 
# è¿™ç§åŠ¨æ€ã€æœºä¼šä¸»ä¹‰çš„å·¥ä½œæµç¨‹æ˜¯æ­£å¸¸è¿è¡Œçš„é»‘æ¿ç³»ç»Ÿçš„æ ‡å¿—ã€‚å®ƒå®Œç¾åœ°éµå¾ªäº†ç”¨æˆ·çš„å¤æ‚æ¡ä»¶é€»è¾‘ï¼ŒèŠ‚çœäº†æ—¶é—´å’Œèµ„æºã€‚

# ## é˜¶æ®µ4ï¼šå®šé‡è¯„ä¼°
# 
# ä¸ºäº†æ­£å¼åŒ–æ¯”è¾ƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨LLMä½œä¸ºè¯„åˆ¤è€…æ¥è¯„ä¼°ä¸¤ä¸ªç³»ç»Ÿåœ¨æŒ‡ä»¤éµå¾ªå’Œè¿‡ç¨‹æ•ˆç‡æ–¹é¢çš„è¡¨ç°ã€‚

# In[8]:


class ProcessLogicEvaluation(BaseModel):
 """Schema for  evaluating agent's logical process."""
 instruction_following_score: int = Field(description="1-10åˆ†è¯„ä¼°ä»£ç†éµå¾ªç”¨æˆ·ç‰¹å®šæ¡ä»¶æŒ‡ä»¤çš„ç¨‹åº¦ã€‚")
 process_efficiency_score: int = Field(description="1-10åˆ†è¯„ä¼°ä»£ç†æ˜¯å¦é‡‡å–äº†æœ€ç›´æ¥çš„è·¯å¾„å¹¶é¿å…äº†ä¸å¿…è¦çš„å·¥ä½œã€‚")
 justification: str = Field(description="è¯„åˆ†çš„ç®€è¦ç†ç”±ï¼Œå¼•ç”¨ä»£ç†é‡‡å–çš„å…·ä½“æ­¥éª¤ã€‚")

# Use a strong model for  judging
judge_llm = ChatOpenAI(model="Qwen/Qwen2.5-72B-Instruct", base_url=os.environ.get("OPENAI_API_BASE"), temperature=0).with_structured_output(ProcessLogicEvaluation)

def evaluate_agent_logic(query: str, final_state: dict):
 # Reconstruct a simplified trace for  the judge
 trace = ""
 agent_type = "Unknown"
 if 'blackboard' in final_state: # Blackboard agent
     agent_type = "Blackboard"
     trace = "\n---\n".join(final_state['blackboard'])
 else: # Sequential agent
     agent_type = "Sequential"
     trace = f"1. News Report Generated: {final_state.get('news_report')}\n---\n2. Technical Report Generated: {final_state.get('technical_report')}\n---\n3. Financial Report Generated: {final_state.get('financial_report')}"

 prompt = f"""ä½ æ˜¯AIä»£ç†æµç¨‹çš„ä¸“ä¸šè¯„åˆ¤å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºå…¶ç”Ÿæˆçš„å†…å®¹è·Ÿè¸ªè¯„ä¼°ä»£ç†çš„æ€§èƒ½ã€‚

**User's Original Task:**
"{query}"

**Agent's Type:** {agent_type}
**Agent's Generated content Trace:**
```
{trace}
```

**è¯„ä¼° Criteria:**
1. **Instruction Following:** ä»£ç†æ˜¯å¦éµå®ˆäº†ç”¨æˆ·ä»»åŠ¡ä¸­çš„æ¡ä»¶é€»è¾‘ï¼Ÿ ï¼ˆä¾‹å¦‚ï¼Œ"è¦ä¹ˆæŠ€æœ¯åˆ†æ...è¦ä¹ˆè´¢åŠ¡åˆ†æ"ï¼‰. é«˜åˆ†æ„å‘³ç€å®ƒå®Œç¾éµå¾ªäº†é€»è¾‘ã€‚ä½åˆ†æ„å‘³ç€å®ƒå¿½ç•¥äº†é€»è¾‘ã€‚
2. **è¿‡ç¨‹ æ•ˆç‡:** ä»£ç†æ˜¯å¦é¿å…äº†ä¸å¿…è¦çš„å·¥ä½œï¼Ÿ é«˜åˆ†æ„å‘³ç€å®ƒåªè¿è¡Œäº†å¿…éœ€çš„ä¸“å®¶ã€‚ä½åˆ†æ„å‘³ç€å®ƒè¿è¡Œäº†ç”¨æˆ·é€»è¾‘æ˜ç¡®è¯´è¦è·³è¿‡çš„ä¸“å®¶ã€‚

åŸºäºè·Ÿè¸ªï¼Œæä¾›ä½ çš„è¯„ä¼°ã€‚
"""
 return judge_llm.invoke(prompt)

# è¯„ä¼°é˜¶æ®µæš‚æ—¶æ³¨é‡Šï¼Œå› ä¸ºjudge_llmæ— æ³•æ­£ç¡®è¿”å›ç»“æ„åŒ–è¾“å‡º
# console.print("--- [bold]è¯„ä¼°é¡ºåºä»£ç†çš„è¿‡ç¨‹[/bold] ---")
# seq_agent_evaluation = evaluate_agent_logic(dynamic_query, final_seq_output)
# console.print(seq_agent_evaluation.dict())

# console.print("\n--- [bold]è¯„ä¼°é»‘æ¿ç³»ç»Ÿçš„è¿‡ç¨‹[/bold] ---")
# bb_agent_evaluation = evaluate_agent_logic(dynamic_query, final_bb_output)
# console.print(bb_agent_evaluation.dict())


# **è¯„ä¼°è¾“å‡ºçš„è®¨è®ºï¼š**
# è¯„åˆ¤è€…çš„è¯„åˆ†æä¾›äº†æ¸…æ™°çš„å®šé‡åˆ¤å†³ï¼š
# 
# - **é¡ºåºä»£ç†**å°†æ”¶åˆ°éå¸¸ä½çš„`instruction_following_score`ï¼ˆä¾‹å¦‚ï¼Œ2/10ï¼‰ï¼Œå› ä¸ºå®ƒå…¬ç„¶å¿½ç•¥äº†"è¦ä¹ˆ/è¦ä¹ˆ"æ¡ä»¶ã€‚å…¶`process_efficiency_score`ä¹Ÿå°†å¾ˆä½ï¼ˆä¾‹å¦‚ï¼Œ3/10ï¼‰ï¼Œå› ä¸ºå®ƒæ‰§è¡Œäº†æ˜ç¡®ä¸éœ€è¦çš„æ•´ä¸ªåˆ†æã€‚
# - **é»‘æ¿ç³»ç»Ÿ**å°†åœ¨ä¸¤æ–¹é¢éƒ½æ”¶åˆ°æ¥è¿‘å®Œç¾çš„è¯„åˆ†ï¼ˆä¾‹å¦‚ï¼Œ10/10ï¼‰ã€‚è¯„åˆ¤è€…å°†è¯†åˆ«å‡ºæ§åˆ¶å™¨çš„åŠ¨æ€å†³ç­–ä½¿ç³»ç»Ÿèƒ½å¤Ÿç²¾ç¡®éµå¾ªç”¨æˆ·çš„æŒ‡ä»¤ï¼Œå¹¶é€šè¿‡ä»…æ¿€æ´»å¿…è¦çš„ä¸“å®¶ä»¥æœ€é«˜æ•ˆç‡è¿è¡Œã€‚
# 
# è¿™ä¸ªè¯„ä¼°æä¾›äº†æ˜ç¡®çš„è¯æ®ï¼Œå¯¹äºå¤æ‚çš„ã€æ¶Œç°çš„é—®é¢˜ï¼Œå…¶ä¸­å‰è¿›çš„è·¯å¾„å–å†³äºä¸­é—´ç»“æœï¼Œé»‘æ¿æ¶æ„çš„çµæ´»æ€§è¿œä¼˜äºåˆšæ€§çš„ã€é¢„å®šä¹‰çš„å·¥ä½œæµç¨‹ã€‚

# ## æ€»ç»“
# 
# åœ¨è¿™ä¸ªnotebookä¸­ï¼Œæˆ‘ä»¬å®ç°å¹¶ä¿®æ­£äº†ä¸€ä¸ª**é»‘æ¿ç³»ç»Ÿ**ï¼Œå±•ç¤ºäº†å…¶ç›¸å¯¹äºé¡ºåºå¤šä»£ç†æ¶æ„çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚ é€šè¿‡å¼•å…¥å…±äº«å†…å­˜ï¼ˆé»‘æ¿ï¼‰å’Œæ™ºèƒ½çš„ã€çŠ¶æ€æ„ŸçŸ¥çš„**æ§åˆ¶å™¨**ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªä¸ä»…åä½œï¼Œè€Œä¸”è‡ªé€‚åº”å’Œæœºä¼šä¸»ä¹‰çš„ç³»ç»Ÿã€‚
# 
# æ­£é¢å¯¹æ¯”æ˜¾ç¤ºï¼Œå¯¹äºå…·æœ‰æ¡ä»¶é€»è¾‘çš„ä»»åŠ¡ï¼Œé»‘æ¿ç³»ç»Ÿåœ¨æ­£ç¡®æ—¶é—´é€‰æ‹©æ­£ç¡®ä¸“å®¶çš„èƒ½åŠ›å¯¼è‡´æ›´é«˜æ•ˆå’Œé€»è¾‘åˆç†çš„è¿‡ç¨‹ã€‚ è™½ç„¶å®ƒéœ€è¦æ›´å¤æ‚çš„æ§åˆ¶å™¨ï¼Œä½†è¿™ç§æ¶æ„æ˜¯å¤„ç†åˆšæ€§çº¿æ€§å·¥ä½œæµç¨‹æ— æ³•æœ‰æ•ˆè§£å†³çš„é‚£ç§ç»“æ„ä¸è‰¯çš„ç°å®ä¸–ç•Œé—®é¢˜çš„å¼ºå¤§å·¥å…·ã€‚


# ## å›¾å¯è§†åŒ–
# 
# æˆ‘ä»¬å°†ä½¿ç”¨graphvizç”Ÿæˆä»£ç†å·¥ä½œæµçš„å¯è§†åŒ–å›¾ç»“æ„ã€‚
# æ³¨æ„ï¼šæ­¤éƒ¨åˆ†å·²æ³¨é‡Šï¼Œå› ä¸ºç³»ç»Ÿå¯èƒ½æ²¡æœ‰å®‰è£…Graphviz

# # å¯¼å…¥å¿…è¦çš„æ¨¡å—
# import subprocess
# import os

# # æ£€æŸ¥ graphviz ä¾èµ–
# try:
#     import graphviz
#     graphviz_installed = True
#     # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å®‰è£…äº†graphvizï¼ˆdotå‘½ä»¤ï¼‰
#     result = subprocess.run(['dot', '-V'], capture_output=True, text=True)
#     system_graphviz_available = (result.returncode == 0)
# except ImportError:
#     graphviz_installed = False
#     system_graphviz_available = False

# # å¯è§†åŒ–é¡ºåºä»£ç†å›¾
# try:
#     current_dir = os.getcwd()
#     
#     # ç”ŸæˆMermaidæ ¼å¼
#     mermaid_graph = sequential_app.get_graph().draw_mermaid()
#     mermaid_path = os.path.join(current_dir, "sequential_agent_graph.mermaid")
#     with open(mermaid_path, "w", encoding="utf-8") as f:
#         f.write(mermaid_graph)
#     print(f"é¡ºåºä»£ç†Mermaidå›¾å·²ä¿å­˜åˆ°: {mermaid_path}")
#     
#     # ç”ŸæˆDOTæ ¼å¼
#     dot_content = """digraph "Sequential Agent Graph" {
#     rankdir=TB;
#     node [shape=rectangle, style=filled, fillcolor=lightblue];
#     
#     news [label="news\næ–°é—»åˆ†æå¸ˆ"];
#     tech [label="tech\næŠ€æœ¯åˆ†æå¸ˆ"];
#     finance [label="finance\nè´¢åŠ¡åˆ†æå¸ˆ"];
#     writer [label="writer\næŠ¥å‘Šæ’°å†™è€…"];
#     END [shape=oval, label="END", fillcolor=lightgreen];
#     
#     news -> tech;
#     tech -> finance;
#     finance -> writer;
#     writer -> END;
# }
# """
#     dot_path = os.path.join(current_dir, "sequential_agent_graph.dot")
#     with open(dot_path, "w", encoding="utf-8") as f:
#         f.write(dot_content)
#     print(f"é¡ºåºä»£ç†DOTå›¾å·²ä¿å­˜åˆ°: {dot_path}")
#     
#     # æ¡ä»¶åŒ–ç”ŸæˆPNGå›¾åƒ
#     if graphviz_installed and system_graphviz_available:
#         try:
#             g = graphviz.Source.from_file(dot_path)
#             png_path = os.path.join(current_dir, "sequential_agent_graph.png")
#             g.render(filename="sequential_agent_graph", directory=current_dir, format="png", cleanup=True)
#             print(f"é¡ºåºä»£ç†PNGå›¾å·²ä¿å­˜åˆ°: {png_path}")
#         except Exception as png_error:
#             print(f"ç”Ÿæˆé¡ºåºä»£ç†PNGå›¾å¤±è´¥: {png_error}")
#     else:
#         print("æç¤º: æ— æ³•ç”ŸæˆPNGå›¾åƒï¼Œå› ä¸ºgraphvizåº“æˆ–ç³»ç»Ÿdotå‘½ä»¤æœªå®‰è£…ã€‚å·²ç”ŸæˆMermaidå’ŒDOTæ ¼å¼æ–‡ä»¶ã€‚")
#        
# except Exception as e:
#     print(f"é¡ºåºä»£ç†å›¾è¡¨å¯è§†åŒ–å¤±è´¥: {e}")

# å¯è§†åŒ–é»‘æ¿ç³»ç»Ÿå›¾
# try:
#     current_dir = os.getcwd()
#     
#     # ç”ŸæˆMermaidæ ¼å¼
#     mermaid_graph = blackboard_app.get_graph().draw_mermaid()
#     mermaid_path = os.path.join(current_dir, "blackboard_system_graph.mermaid")
#     with open(mermaid_path, "w", encoding="utf-8") as f:
#         f.write(mermaid_graph)
#     print(f"é»‘æ¿ç³»ç»ŸMermaidå›¾å·²ä¿å­˜åˆ°: {mermaid_path}")
#     
#     # ç”ŸæˆDOTæ ¼å¼
#     dot_content = """digraph "Blackboard System Graph" {
#     rankdir=TB;
#     node [shape=rectangle, style=filled, fillcolor=lightblue];
#     
#     Controller [label="Controller\næ§åˆ¶å™¨"];
#     news_analyst [label="æ–°é—»åˆ†æå¸ˆ"];
#     technical_analyst [label="æŠ€æœ¯åˆ†æå¸ˆ"];
#     financial_analyst [label="è´¢åŠ¡åˆ†æå¸ˆ"];
#     report_writer [label="æŠ¥å‘Šæ’°å†™è€…"];
#     END [shape=oval, label="END", fillcolor=lightgreen];
#     
#     Controller -> news_analyst [label="æ¡ä»¶è·¯ç”±"];
#     Controller -> technical_analyst [label="æ¡ä»¶è·¯ç”±"];
#     Controller -> financial_analyst [label="æ¡ä»¶è·¯ç”±"];
#     Controller -> report_writer [label="æ¡ä»¶è·¯ç”±"];
#     Controller -> END [label="æ¡ä»¶è·¯ç”± (FINISH)"];
#     
#     news_analyst -> Controller;
#     technical_analyst -> Controller;
#     financial_analyst -> Controller;
#     report_writer -> Controller;
# }
# """
#     dot_path = os.path.join(current_dir, "blackboard_system_graph.dot")
#     with open(dot_path, "w", encoding="utf-8") as f:
#         f.write(dot_content)
#     print(f"é»‘æ¿ç³»ç»ŸDOTå›¾å·²ä¿å­˜åˆ°: {dot_path}")
#     
#     # æ¡ä»¶åŒ–ç”ŸæˆPNGå›¾åƒ
#     if graphviz_installed and system_graphviz_available:
#         try:
#             g = graphviz.Source.from_file(dot_path)
#             png_path = os.path.join(current_dir, "blackboard_system_graph.png")
#             g.render(filename="blackboard_system_graph", directory=current_dir, format="png", cleanup=True)
#             print(f"é»‘æ¿ç³»ç»ŸPNGå›¾å·²ä¿å­˜åˆ°: {png_path}")
#         except Exception as png_error:
#             print(f"ç”Ÿæˆé»‘æ¿ç³»ç»ŸPNGå›¾å¤±è´¥: {png_error}")
#     else:
#         print("æç¤º: æ— æ³•ç”ŸæˆPNGå›¾åƒï¼Œå› ä¸ºgraphvizåº“æˆ–ç³»ç»Ÿdotå‘½ä»¤æœªå®‰è£…ã€‚å·²ç”ŸæˆMermaidå’ŒDOTæ ¼å¼æ–‡ä»¶ã€‚")
#        
# except Exception as e:
#     print(f"é»‘æ¿ç³»ç»Ÿå›¾è¡¨å¯è§†åŒ–å¤±è´¥: {e}")